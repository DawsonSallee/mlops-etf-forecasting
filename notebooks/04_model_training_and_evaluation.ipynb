{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dca4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import shap\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mlflow.set_tracking_uri(\"../mlruns\")\n",
    "\n",
    "# Load your processed data\n",
    "DATA_PATH = '../data/processed/etf_features.parquet'\n",
    "data = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb7dc1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2380\n",
      "Test set size: 908\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Invalid parent directory '..\\mlruns\\.trash'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mETF_Trend_Prediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:183\u001b[39m, in \u001b[36mset_experiment\u001b[39m\u001b[34m(experiment_name, experiment_id)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _experiment_lock:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         experiment = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment:\n\u001b[32m    185\u001b[39m             _logger.info(\n\u001b[32m    186\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mExperiment with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist. Creating a new experiment.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    187\u001b[39m                 experiment_name,\n\u001b[32m    188\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:261\u001b[39m, in \u001b[36mTrackingServiceClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m    254\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[33;03m        name: The experiment name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    259\u001b[39m \u001b[33;03m        :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:392\u001b[39m, in \u001b[36mFileStore.get_experiment_by_name\u001b[39m\u001b[34m(self, experiment_name)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_experiments(\n\u001b[32m    386\u001b[39m         view_type=ViewType.ALL,\n\u001b[32m    387\u001b[39m         max_results=number_to_get,\n\u001b[32m    388\u001b[39m         filter_string=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mname = \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    389\u001b[39m         page_token=next_page_token,\n\u001b[32m    390\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m experiments = \u001b[43mget_results_from_paginated_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaginated_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpagination_wrapper_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_results_per_page\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEARCH_MAX_RESULTS_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m experiments[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(experiments) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\utils\\__init__.py:238\u001b[39m, in \u001b[36mget_results_from_paginated_fn\u001b[39m\u001b[34m(paginated_fn, max_results_per_page, max_results)\u001b[39m\n\u001b[32m    236\u001b[39m     page_results = paginated_fn(num_to_get, next_page_token)\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     page_results = \u001b[43mpaginated_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results_per_page\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_page_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m all_results.extend(page_results)\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(page_results, \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m page_results.token:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:385\u001b[39m, in \u001b[36mFileStore.get_experiment_by_name.<locals>.pagination_wrapper_func\u001b[39m\u001b[34m(number_to_get, next_page_token)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msearch_experiments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mview_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mViewType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumber_to_get\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname = \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpage_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnext_page_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:360\u001b[39m, in \u001b[36mFileStore.search_experiments\u001b[39m\u001b[34m(self, view_type, max_results, filter_string, order_by, page_token)\u001b[39m\n\u001b[32m    358\u001b[39m     experiment_ids += \u001b[38;5;28mself\u001b[39m._get_active_experiments(full_path=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m view_type == ViewType.DELETED_ONLY \u001b[38;5;129;01mor\u001b[39;00m view_type == ViewType.ALL:\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m     experiment_ids += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_deleted_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m experiments = []\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m exp_id \u001b[38;5;129;01min\u001b[39;00m experiment_ids:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:332\u001b[39m, in \u001b[36mFileStore._get_deleted_experiments\u001b[39m\u001b[34m(self, full_path)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_deleted_experiments\u001b[39m(\u001b[38;5;28mself\u001b[39m, full_path=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlist_subdirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrash_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\utils\\file_utils.py:160\u001b[39m, in \u001b[36mlist_subdirs\u001b[39m\u001b[34m(dir_name, full_path)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlist_subdirs\u001b[39m(dir_name, full_path=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    149\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[33;03m    Equivalent to UNIX command:\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[33;03m      ``find $dir_name -depth 1 -type d``\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m        list of all directories directly under 'dir_name'.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlist_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43misdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\mlflow\\utils\\file_utils.py:143\u001b[39m, in \u001b[36mlist_all\u001b[39m\u001b[34m(root, filter_func, full_path)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"List all entities directly under 'dir_name' that satisfy 'filter_func'\u001b[39;00m\n\u001b[32m    132\u001b[39m \n\u001b[32m    133\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \n\u001b[32m    141\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(root):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid parent directory \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m matches = [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m os.listdir(root) \u001b[38;5;28;01mif\u001b[39;00m filter_func(os.path.join(root, x))]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [os.path.join(root, m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches] \u001b[38;5;28;01mif\u001b[39;00m full_path \u001b[38;5;28;01melse\u001b[39;00m matches\n",
      "\u001b[31mException\u001b[39m: Invalid parent directory '..\\mlruns\\.trash'"
     ]
    }
   ],
   "source": [
    "# Define the chronological split point\n",
    "# For example, use data up to the end of 2021 for training, and 2022 onwards for testing.\n",
    "split_date = '2022-01-01'\n",
    "X_train, X_test = X.loc[:split_date], X.loc[split_date:]\n",
    "y_train, y_test = y.loc[:split_date], y.loc[split_date:]\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "mlflow.set_experiment(\"ETF_Trend_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.6968\n",
      "Random Forest F1 Score: 0.6299\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Baseline\"):\n",
    "    model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    y_pred_lr = model_lr.predict(X_test)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred_lr))\n",
    "    mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred_lr))\n",
    "    print(f\"Logistic Regression F1 Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Train Random Forest\n",
    "with mlflow.start_run(run_name=\"RandomForest_Baseline\"):\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred_rf))\n",
    "    mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred_rf))\n",
    "    print(f\"Random Forest F1 Score: {f1_score(y_test, y_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dee337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    # Use TimeSeriesSplit for robust cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring='f1', n_jobs=-1).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 11:58:55,288] A new study created in memory with name: no-name-8622c2a1-e449-43e8-9198-28703ccaefe6\n",
      "[I 2025-08-24 11:59:09,168] Trial 0 finished with value: 0.5480327354726395 and parameters: {'n_estimators': 187, 'max_depth': 7, 'learning_rate': 0.05217803027038593, 'subsample': 0.6106891276360176, 'colsample_bytree': 0.5820999574471655, 'gamma': 1.0266789493466666}. Best is trial 0 with value: 0.5480327354726395.\n",
      "[I 2025-08-24 11:59:19,507] Trial 1 finished with value: 0.5170847390286892 and parameters: {'n_estimators': 595, 'max_depth': 6, 'learning_rate': 0.02488953736849689, 'subsample': 0.7783232472336634, 'colsample_bytree': 0.8568805179952641, 'gamma': 0.7671417420313331}. Best is trial 0 with value: 0.5480327354726395.\n",
      "[I 2025-08-24 11:59:27,722] Trial 2 finished with value: 0.5180736012010428 and parameters: {'n_estimators': 735, 'max_depth': 7, 'learning_rate': 0.15258104400569464, 'subsample': 0.7963086005039028, 'colsample_bytree': 0.8264909679682776, 'gamma': 3.7506565856836653}. Best is trial 0 with value: 0.5480327354726395.\n",
      "[I 2025-08-24 11:59:33,460] Trial 3 finished with value: 0.5442884812230087 and parameters: {'n_estimators': 250, 'max_depth': 10, 'learning_rate': 0.15663754622710985, 'subsample': 0.5695889371819776, 'colsample_bytree': 0.8680168714486354, 'gamma': 3.7213391153384068}. Best is trial 0 with value: 0.5480327354726395.\n",
      "[I 2025-08-24 11:59:34,092] Trial 4 finished with value: 0.5487730172739026 and parameters: {'n_estimators': 883, 'max_depth': 6, 'learning_rate': 0.28449239229622375, 'subsample': 0.937856980072914, 'colsample_bytree': 0.9339847543859185, 'gamma': 3.2783193427029222}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:34,422] Trial 5 finished with value: 0.5053348359080563 and parameters: {'n_estimators': 205, 'max_depth': 6, 'learning_rate': 0.23183539682174162, 'subsample': 0.8356891612715271, 'colsample_bytree': 0.7124884450291469, 'gamma': 1.9014243032639688}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:34,820] Trial 6 finished with value: 0.5145344565124901 and parameters: {'n_estimators': 399, 'max_depth': 8, 'learning_rate': 0.19260494730452135, 'subsample': 0.6796075304292785, 'colsample_bytree': 0.5711432631827231, 'gamma': 3.1417916515323263}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:35,313] Trial 7 finished with value: 0.5105585977639397 and parameters: {'n_estimators': 644, 'max_depth': 10, 'learning_rate': 0.1479062799207255, 'subsample': 0.9589542329266706, 'colsample_bytree': 0.67851099417955, 'gamma': 3.122243359227901}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:35,719] Trial 8 finished with value: 0.5283749133597528 and parameters: {'n_estimators': 601, 'max_depth': 9, 'learning_rate': 0.29234589854715665, 'subsample': 0.8343115156816541, 'colsample_bytree': 0.990913706767893, 'gamma': 4.738682074399023}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:36,831] Trial 9 finished with value: 0.536795015010595 and parameters: {'n_estimators': 845, 'max_depth': 6, 'learning_rate': 0.06307759344975761, 'subsample': 0.5077048460600024, 'colsample_bytree': 0.7379329570659496, 'gamma': 2.388004199809748}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:37,482] Trial 10 finished with value: 0.5304757559844375 and parameters: {'n_estimators': 995, 'max_depth': 3, 'learning_rate': 0.28325142357714167, 'subsample': 0.993480397182549, 'colsample_bytree': 0.9956916892929966, 'gamma': 4.639308163559717}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:38,246] Trial 11 finished with value: 0.5178805216160091 and parameters: {'n_estimators': 410, 'max_depth': 4, 'learning_rate': 0.08569215392346956, 'subsample': 0.6342063363467807, 'colsample_bytree': 0.5543432358622613, 'gamma': 0.2179559994014313}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:38,744] Trial 12 finished with value: 0.5009713594619872 and parameters: {'n_estimators': 408, 'max_depth': 5, 'learning_rate': 0.09089926680616056, 'subsample': 0.9069978434845118, 'colsample_bytree': 0.6321902940157401, 'gamma': 1.666669785368153}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:46,913] Trial 13 finished with value: 0.5400742571448347 and parameters: {'n_estimators': 879, 'max_depth': 8, 'learning_rate': 0.01016604052253281, 'subsample': 0.6874438299303975, 'colsample_bytree': 0.9050367663479876, 'gamma': 0.9856324390369522}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:47,333] Trial 14 finished with value: 0.5069764270626761 and parameters: {'n_estimators': 101, 'max_depth': 7, 'learning_rate': 0.2341925379937117, 'subsample': 0.7193998262506837, 'colsample_bytree': 0.5090294039207529, 'gamma': 1.4401965175922578}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:48,100] Trial 15 finished with value: 0.5038288840444116 and parameters: {'n_estimators': 465, 'max_depth': 5, 'learning_rate': 0.10990551394275738, 'subsample': 0.5963861646255852, 'colsample_bytree': 0.7984134302027275, 'gamma': 2.5731964574155315}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:49,235] Trial 16 finished with value: 0.5417737693676445 and parameters: {'n_estimators': 778, 'max_depth': 8, 'learning_rate': 0.2461024077051603, 'subsample': 0.8754700877217756, 'colsample_bytree': 0.6335831526492544, 'gamma': 0.22227126204651082}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:50,120] Trial 17 finished with value: 0.5367449051853735 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.20012453894228271, 'subsample': 0.5078388831405408, 'colsample_bytree': 0.9405763219636308, 'gamma': 4.001030375657039}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:50,929] Trial 18 finished with value: 0.5384404220357825 and parameters: {'n_estimators': 298, 'max_depth': 7, 'learning_rate': 0.049160330954112624, 'subsample': 0.7504313898731665, 'colsample_bytree': 0.7782825983094752, 'gamma': 2.3908049520420898}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:51,100] Trial 19 finished with value: 0.5258099638325896 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.1273398606681464, 'subsample': 0.9233576540405259, 'colsample_bytree': 0.6269044231248032, 'gamma': 3.0433122860434327}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:51,966] Trial 20 finished with value: 0.5374489847032231 and parameters: {'n_estimators': 703, 'max_depth': 9, 'learning_rate': 0.1890655990008061, 'subsample': 0.6311411956739481, 'colsample_bytree': 0.501794059501452, 'gamma': 0.9541382989802838}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:52,323] Trial 21 finished with value: 0.5460072649243457 and parameters: {'n_estimators': 249, 'max_depth': 10, 'learning_rate': 0.2676631416334349, 'subsample': 0.5727145259594149, 'colsample_bytree': 0.8852056077235737, 'gamma': 3.8813870489742905}. Best is trial 4 with value: 0.5487730172739026.\n",
      "[I 2025-08-24 11:59:52,703] Trial 22 finished with value: 0.5525930849021454 and parameters: {'n_estimators': 328, 'max_depth': 9, 'learning_rate': 0.26920761080494204, 'subsample': 0.5687318946424067, 'colsample_bytree': 0.9337641185016027, 'gamma': 4.066787933336489}. Best is trial 22 with value: 0.5525930849021454.\n",
      "[I 2025-08-24 11:59:53,174] Trial 23 finished with value: 0.5448968821788206 and parameters: {'n_estimators': 502, 'max_depth': 9, 'learning_rate': 0.2593869171306503, 'subsample': 0.5449125078349749, 'colsample_bytree': 0.9321920834850707, 'gamma': 4.559789419177749}. Best is trial 22 with value: 0.5525930849021454.\n",
      "[I 2025-08-24 11:59:53,540] Trial 24 finished with value: 0.5697107689014167 and parameters: {'n_estimators': 365, 'max_depth': 8, 'learning_rate': 0.2990181430646186, 'subsample': 0.6255183641654397, 'colsample_bytree': 0.9712638806780841, 'gamma': 4.254206678691501}. Best is trial 24 with value: 0.5697107689014167.\n",
      "[I 2025-08-24 11:59:53,866] Trial 25 finished with value: 0.570204967338614 and parameters: {'n_estimators': 344, 'max_depth': 8, 'learning_rate': 0.2992795291558727, 'subsample': 0.6842870212016523, 'colsample_bytree': 0.9536257243650332, 'gamma': 4.297696763848467}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:54,186] Trial 26 finished with value: 0.5406095877950958 and parameters: {'n_estimators': 332, 'max_depth': 8, 'learning_rate': 0.2983696332611206, 'subsample': 0.669679952641409, 'colsample_bytree': 0.9559185494789468, 'gamma': 4.280398316765917}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:54,532] Trial 27 finished with value: 0.5465184124325598 and parameters: {'n_estimators': 340, 'max_depth': 9, 'learning_rate': 0.22051938337914684, 'subsample': 0.6493465733348112, 'colsample_bytree': 0.9725772949303654, 'gamma': 4.936304803857746}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:54,943] Trial 28 finished with value: 0.5188462976876338 and parameters: {'n_estimators': 497, 'max_depth': 8, 'learning_rate': 0.2541119696656107, 'subsample': 0.7101678381901645, 'colsample_bytree': 0.9099919846076965, 'gamma': 4.267432677560496}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:55,246] Trial 29 finished with value: 0.5409351815561609 and parameters: {'n_estimators': 166, 'max_depth': 9, 'learning_rate': 0.27241386578047744, 'subsample': 0.5963997912780544, 'colsample_bytree': 0.8318028304891139, 'gamma': 3.449616729781324}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:55,637] Trial 30 finished with value: 0.5429531959337 and parameters: {'n_estimators': 353, 'max_depth': 7, 'learning_rate': 0.22226094731233084, 'subsample': 0.5324755126551193, 'colsample_bytree': 0.904892904588044, 'gamma': 4.255468101645488}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:55,981] Trial 31 finished with value: 0.5257542294233217 and parameters: {'n_estimators': 273, 'max_depth': 6, 'learning_rate': 0.281697873134653, 'subsample': 0.6022852687350939, 'colsample_bytree': 0.9547202657714398, 'gamma': 3.489393782265357}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:56,433] Trial 32 finished with value: 0.5394150537846227 and parameters: {'n_estimators': 448, 'max_depth': 8, 'learning_rate': 0.2979138902402731, 'subsample': 0.7114269725350354, 'colsample_bytree': 0.9380622472366359, 'gamma': 2.7511037670289356}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:56,832] Trial 33 finished with value: 0.5372891263463269 and parameters: {'n_estimators': 544, 'max_depth': 7, 'learning_rate': 0.2719999651879536, 'subsample': 0.784519285988769, 'colsample_bytree': 0.9986404261686678, 'gamma': 4.181896689490653}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:57,176] Trial 34 finished with value: 0.5454179380384769 and parameters: {'n_estimators': 201, 'max_depth': 9, 'learning_rate': 0.246411836614348, 'subsample': 0.7475787467282867, 'colsample_bytree': 0.848143735385458, 'gamma': 3.5518153066678697}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:57,610] Trial 35 finished with value: 0.5527477888633627 and parameters: {'n_estimators': 378, 'max_depth': 10, 'learning_rate': 0.2998070871869659, 'subsample': 0.5633439325010859, 'colsample_bytree': 0.8845990514639208, 'gamma': 4.5301083128296185}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:57,980] Trial 36 finished with value: 0.5469527415649725 and parameters: {'n_estimators': 361, 'max_depth': 10, 'learning_rate': 0.26873593725859307, 'subsample': 0.570453693668239, 'colsample_bytree': 0.8790600780714578, 'gamma': 4.9076847136174715}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:58,359] Trial 37 finished with value: 0.5620049680648764 and parameters: {'n_estimators': 308, 'max_depth': 10, 'learning_rate': 0.28430695381122734, 'subsample': 0.537801995203709, 'colsample_bytree': 0.8594029881125635, 'gamma': 4.562256622289597}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:58,670] Trial 38 finished with value: 0.5534704855610374 and parameters: {'n_estimators': 269, 'max_depth': 10, 'learning_rate': 0.2986979426094954, 'subsample': 0.5447480582842498, 'colsample_bytree': 0.8025125724487983, 'gamma': 4.48583098655996}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:59,017] Trial 39 finished with value: 0.5641345512340517 and parameters: {'n_estimators': 241, 'max_depth': 10, 'learning_rate': 0.20753505203621025, 'subsample': 0.5338031189632476, 'colsample_bytree': 0.7955801110217839, 'gamma': 3.796196604003205}. Best is trial 25 with value: 0.570204967338614.\n",
      "[I 2025-08-24 11:59:59,355] Trial 40 finished with value: 0.5739539912490078 and parameters: {'n_estimators': 222, 'max_depth': 10, 'learning_rate': 0.17176808646438887, 'subsample': 0.6222198159758612, 'colsample_bytree': 0.7494683285704219, 'gamma': 3.890603101261515}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 11:59:59,672] Trial 41 finished with value: 0.5188709079570384 and parameters: {'n_estimators': 225, 'max_depth': 10, 'learning_rate': 0.20406912821720752, 'subsample': 0.6536512824623483, 'colsample_bytree': 0.7521754778689704, 'gamma': 3.784835728162418}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 11:59:59,961] Trial 42 finished with value: 0.5272250302830475 and parameters: {'n_estimators': 155, 'max_depth': 10, 'learning_rate': 0.17427158350931315, 'subsample': 0.6205152899343147, 'colsample_bytree': 0.7084379853667936, 'gamma': 3.649681152754998}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:00,422] Trial 43 finished with value: 0.5503337216471211 and parameters: {'n_estimators': 280, 'max_depth': 9, 'learning_rate': 0.16562785883339234, 'subsample': 0.5251684345124675, 'colsample_bytree': 0.808715592189256, 'gamma': 3.9831724672923543}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:00,748] Trial 44 finished with value: 0.5506318455099313 and parameters: {'n_estimators': 151, 'max_depth': 10, 'learning_rate': 0.13113966105662928, 'subsample': 0.684707474840025, 'colsample_bytree': 0.7664050955207615, 'gamma': 4.414947462491993}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:01,036] Trial 45 finished with value: 0.5679701199655983 and parameters: {'n_estimators': 223, 'max_depth': 10, 'learning_rate': 0.21781738522278832, 'subsample': 0.5883871208783075, 'colsample_bytree': 0.7119284979656909, 'gamma': 4.727908225064492}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:01,303] Trial 46 finished with value: 0.527567070565264 and parameters: {'n_estimators': 220, 'max_depth': 8, 'learning_rate': 0.17938575258256087, 'subsample': 0.6507564879488804, 'colsample_bytree': 0.6757388549631875, 'gamma': 4.73425419140343}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:01,736] Trial 47 finished with value: 0.49737992220850763 and parameters: {'n_estimators': 247, 'max_depth': 9, 'learning_rate': 0.14723988363447543, 'subsample': 0.6050850196487915, 'colsample_bytree': 0.7056890201592116, 'gamma': 3.246281675223576}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:01,989] Trial 48 finished with value: 0.5583431759052926 and parameters: {'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.22069800974415255, 'subsample': 0.591040228665502, 'colsample_bytree': 0.7365965747865093, 'gamma': 4.990736329537683}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:02,449] Trial 49 finished with value: 0.5313353522953914 and parameters: {'n_estimators': 424, 'max_depth': 10, 'learning_rate': 0.20321169574160688, 'subsample': 0.6257532186655697, 'colsample_bytree': 0.6805905502367249, 'gamma': 2.907115538938097}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:02,853] Trial 50 finished with value: 0.5430309031707459 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.23660718162568808, 'subsample': 0.5012612393952443, 'colsample_bytree': 0.7322511803975433, 'gamma': 1.9967809126878078}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:03,207] Trial 51 finished with value: 0.5680108033948544 and parameters: {'n_estimators': 308, 'max_depth': 10, 'learning_rate': 0.2850146243792176, 'subsample': 0.5475740478802484, 'colsample_bytree': 0.8451726495730049, 'gamma': 4.703264749137121}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:03,487] Trial 52 finished with value: 0.5666739490138145 and parameters: {'n_estimators': 202, 'max_depth': 10, 'learning_rate': 0.2841819422445562, 'subsample': 0.5788794535897495, 'colsample_bytree': 0.7816190224952206, 'gamma': 4.809605523254327}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:03,801] Trial 53 finished with value: 0.5406356091829867 and parameters: {'n_estimators': 301, 'max_depth': 10, 'learning_rate': 0.2847449785096754, 'subsample': 0.6657732348520717, 'colsample_bytree': 0.8329188558217248, 'gamma': 4.781503294611663}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:04,065] Trial 54 finished with value: 0.5659690659798176 and parameters: {'n_estimators': 197, 'max_depth': 9, 'learning_rate': 0.2553609247989167, 'subsample': 0.5806020757774806, 'colsample_bytree': 0.7771284155191742, 'gamma': 4.705498486787702}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:04,321] Trial 55 finished with value: 0.5471895811416971 and parameters: {'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.2853781875770399, 'subsample': 0.6387720982680748, 'colsample_bytree': 0.9727661112794617, 'gamma': 4.119036955078184}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:04,649] Trial 56 finished with value: 0.5498934071100099 and parameters: {'n_estimators': 392, 'max_depth': 7, 'learning_rate': 0.24561795498120953, 'subsample': 0.6207751503584265, 'colsample_bytree': 0.683730480309481, 'gamma': 4.388747601431673}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:04,966] Trial 57 finished with value: 0.5497181909454066 and parameters: {'n_estimators': 307, 'max_depth': 9, 'learning_rate': 0.27618626766602483, 'subsample': 0.5617310268211457, 'colsample_bytree': 0.7563129220139775, 'gamma': 4.801121954637088}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:05,378] Trial 58 finished with value: 0.463069180631454 and parameters: {'n_estimators': 598, 'max_depth': 10, 'learning_rate': 0.2895913365178376, 'subsample': 0.6938773417079924, 'colsample_bytree': 0.6612569225669137, 'gamma': 4.369053068947748}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:05,582] Trial 59 finished with value: 0.5347817507429159 and parameters: {'n_estimators': 198, 'max_depth': 3, 'learning_rate': 0.26288964532191716, 'subsample': 0.6128619724526017, 'colsample_bytree': 0.817221531261654, 'gamma': 4.992733992711384}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:06,005] Trial 60 finished with value: 0.5450093143630605 and parameters: {'n_estimators': 646, 'max_depth': 9, 'learning_rate': 0.2390556833298628, 'subsample': 0.7493272730050302, 'colsample_bytree': 0.7839916113743528, 'gamma': 4.65219789261438}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:06,263] Trial 61 finished with value: 0.556985380583836 and parameters: {'n_estimators': 201, 'max_depth': 9, 'learning_rate': 0.2580849246508045, 'subsample': 0.5772692181585733, 'colsample_bytree': 0.7742109554977612, 'gamma': 4.7021723423361355}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:06,571] Trial 62 finished with value: 0.5519941722362219 and parameters: {'n_estimators': 263, 'max_depth': 9, 'learning_rate': 0.25253343352986113, 'subsample': 0.5849597017402614, 'colsample_bytree': 0.7221740216345909, 'gamma': 3.988760068797054}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:06,818] Trial 63 finished with value: 0.5390307372927717 and parameters: {'n_estimators': 167, 'max_depth': 8, 'learning_rate': 0.27652866013087063, 'subsample': 0.5532705386863674, 'colsample_bytree': 0.7561575841618577, 'gamma': 4.810893639205189}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:07,100] Trial 64 finished with value: 0.5433494070905833 and parameters: {'n_estimators': 224, 'max_depth': 10, 'learning_rate': 0.2910529892931958, 'subsample': 0.5914224803589592, 'colsample_bytree': 0.6945981151567326, 'gamma': 4.5959040288842985}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:07,423] Trial 65 finished with value: 0.5327098785056424 and parameters: {'n_estimators': 330, 'max_depth': 9, 'learning_rate': 0.26298389189754084, 'subsample': 0.6359997204200997, 'colsample_bytree': 0.8431337095291552, 'gamma': 4.284632985438898}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:07,789] Trial 66 finished with value: 0.5259921986567053 and parameters: {'n_estimators': 370, 'max_depth': 10, 'learning_rate': 0.23080719623766138, 'subsample': 0.6071335780402934, 'colsample_bytree': 0.6512287635145311, 'gamma': 4.1637803886904}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:08,682] Trial 67 finished with value: 0.5087554214632065 and parameters: {'n_estimators': 437, 'max_depth': 9, 'learning_rate': 0.2771986155220797, 'subsample': 0.8185190441552243, 'colsample_bytree': 0.9778901945804118, 'gamma': 0.48967588325331857}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:08,962] Trial 68 finished with value: 0.5510103430346127 and parameters: {'n_estimators': 101, 'max_depth': 8, 'learning_rate': 0.21377284933832486, 'subsample': 0.6736219315979438, 'colsample_bytree': 0.9207872296926181, 'gamma': 4.403978895500043}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:09,295] Trial 69 finished with value: 0.5686739886419584 and parameters: {'n_estimators': 285, 'max_depth': 10, 'learning_rate': 0.250532818309257, 'subsample': 0.5203464103318498, 'colsample_bytree': 0.5955712290296986, 'gamma': 4.80919517457198}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:09,616] Trial 70 finished with value: 0.5525078453097182 and parameters: {'n_estimators': 295, 'max_depth': 6, 'learning_rate': 0.2906396369964665, 'subsample': 0.5186275059743776, 'colsample_bytree': 0.6269165657663777, 'gamma': 3.9468233368064203}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:09,880] Trial 71 finished with value: 0.5712975160901991 and parameters: {'n_estimators': 242, 'max_depth': 10, 'learning_rate': 0.2500263513315125, 'subsample': 0.553039923716196, 'colsample_bytree': 0.581584293854709, 'gamma': 4.622986578587468}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:10,172] Trial 72 finished with value: 0.534200963230141 and parameters: {'n_estimators': 241, 'max_depth': 10, 'learning_rate': 0.19192005997653439, 'subsample': 0.5130903651719518, 'colsample_bytree': 0.593197789140342, 'gamma': 4.868534684902357}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:10,500] Trial 73 finished with value: 0.5678909740668249 and parameters: {'n_estimators': 336, 'max_depth': 10, 'learning_rate': 0.24485116840048934, 'subsample': 0.5587190371159261, 'colsample_bytree': 0.5380401932296025, 'gamma': 4.53219794342359}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:10,922] Trial 74 finished with value: 0.5685309680838115 and parameters: {'n_estimators': 467, 'max_depth': 10, 'learning_rate': 0.23070204875317255, 'subsample': 0.5462515296425907, 'colsample_bytree': 0.5352974598318434, 'gamma': 4.518335087610151}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:11,325] Trial 75 finished with value: 0.5297240115121398 and parameters: {'n_estimators': 460, 'max_depth': 10, 'learning_rate': 0.22998496721775402, 'subsample': 0.5428700128645332, 'colsample_bytree': 0.5929897584966547, 'gamma': 4.215836624672768}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:11,742] Trial 76 finished with value: 0.5139825598369708 and parameters: {'n_estimators': 398, 'max_depth': 10, 'learning_rate': 0.2162326151554324, 'subsample': 0.520785725243748, 'colsample_bytree': 0.5257680296363971, 'gamma': 4.437935297582923}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:12,227] Trial 77 finished with value: 0.5361487901690489 and parameters: {'n_estimators': 557, 'max_depth': 5, 'learning_rate': 0.09813358299397595, 'subsample': 0.5518519124973589, 'colsample_bytree': 0.568626806539549, 'gamma': 4.066319769580108}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:12,663] Trial 78 finished with value: 0.5468329579374768 and parameters: {'n_estimators': 483, 'max_depth': 10, 'learning_rate': 0.0688515296215335, 'subsample': 0.7338187969480163, 'colsample_bytree': 0.5490967432465859, 'gamma': 4.5898381087067275}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:12,984] Trial 79 finished with value: 0.5283239684362411 and parameters: {'n_estimators': 279, 'max_depth': 7, 'learning_rate': 0.2657818863720827, 'subsample': 0.5008729975751683, 'colsample_bytree': 0.6114717938909138, 'gamma': 3.712351719983321}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:13,311] Trial 80 finished with value: 0.5567454063271692 and parameters: {'n_estimators': 353, 'max_depth': 10, 'learning_rate': 0.22847850632680075, 'subsample': 0.5343483268600673, 'colsample_bytree': 0.5255912317057106, 'gamma': 4.341506017766278}. Best is trial 40 with value: 0.5739539912490078.\n",
      "[I 2025-08-24 12:00:13,632] Trial 81 finished with value: 0.585264759407509 and parameters: {'n_estimators': 323, 'max_depth': 10, 'learning_rate': 0.2430417370516384, 'subsample': 0.5577559366087779, 'colsample_bytree': 0.5532866559353881, 'gamma': 4.516002265875756}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:14,013] Trial 82 finished with value: 0.5560465361396244 and parameters: {'n_estimators': 415, 'max_depth': 10, 'learning_rate': 0.24381292828123918, 'subsample': 0.5256960642733776, 'colsample_bytree': 0.5651205710297384, 'gamma': 4.641101133960088}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:14,345] Trial 83 finished with value: 0.5567663289957462 and parameters: {'n_estimators': 316, 'max_depth': 10, 'learning_rate': 0.2517603193896065, 'subsample': 0.5650860299044298, 'colsample_bytree': 0.5876569727451019, 'gamma': 4.497310584008342}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:15,075] Trial 84 finished with value: 0.5717362921757668 and parameters: {'n_estimators': 371, 'max_depth': 10, 'learning_rate': 0.18219853604965536, 'subsample': 0.5494159365460985, 'colsample_bytree': 0.6072204893645619, 'gamma': 1.2113367987857693}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:15,794] Trial 85 finished with value: 0.5428998099910053 and parameters: {'n_estimators': 381, 'max_depth': 9, 'learning_rate': 0.14933717454148748, 'subsample': 0.546337989629451, 'colsample_bytree': 0.517113678932578, 'gamma': 1.1162409909611277}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:16,373] Trial 86 finished with value: 0.5458444723379926 and parameters: {'n_estimators': 351, 'max_depth': 10, 'learning_rate': 0.1601694974373257, 'subsample': 0.5293123781476533, 'colsample_bytree': 0.6051271810073494, 'gamma': 2.0712012382852585}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:16,922] Trial 87 finished with value: 0.5431688636309011 and parameters: {'n_estimators': 531, 'max_depth': 10, 'learning_rate': 0.14058052977617577, 'subsample': 0.6971034245485774, 'colsample_bytree': 0.5478287023519526, 'gamma': 2.2729452226897147}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:17,516] Trial 88 finished with value: 0.5521135212217746 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.1806844568499069, 'subsample': 0.5118809457880914, 'colsample_bytree': 0.5755790734665839, 'gamma': 1.273096459063086}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:19,879] Trial 89 finished with value: 0.5593928068149518 and parameters: {'n_estimators': 431, 'max_depth': 10, 'learning_rate': 0.12147974251093016, 'subsample': 0.5988267879723219, 'colsample_bytree': 0.9568310953476229, 'gamma': 0.08438487522778493}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:20,377] Trial 90 finished with value: 0.4974067088678663 and parameters: {'n_estimators': 292, 'max_depth': 10, 'learning_rate': 0.1846448416460863, 'subsample': 0.8801213311853893, 'colsample_bytree': 0.6088559997257389, 'gamma': 1.7384835475558829}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:21,002] Trial 91 finished with value: 0.5310431393494176 and parameters: {'n_estimators': 930, 'max_depth': 10, 'learning_rate': 0.20989518089194484, 'subsample': 0.5693420892678952, 'colsample_bytree': 0.5587084762962305, 'gamma': 3.850890655376164}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:21,321] Trial 92 finished with value: 0.5676298449651933 and parameters: {'n_estimators': 314, 'max_depth': 10, 'learning_rate': 0.1965016550408117, 'subsample': 0.5552413643591447, 'colsample_bytree': 0.6396493871324532, 'gamma': 4.944008855764034}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:21,681] Trial 93 finished with value: 0.552526460808044 and parameters: {'n_estimators': 231, 'max_depth': 10, 'learning_rate': 0.17073195944704653, 'subsample': 0.5869575649083769, 'colsample_bytree': 0.5787842949614223, 'gamma': 4.268048983272679}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:22,029] Trial 94 finished with value: 0.5494247205365823 and parameters: {'n_estimators': 364, 'max_depth': 9, 'learning_rate': 0.2233746409267085, 'subsample': 0.5407754943363919, 'colsample_bytree': 0.5055784133839774, 'gamma': 4.699995624389023}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:22,306] Trial 95 finished with value: 0.5310273533203433 and parameters: {'n_estimators': 260, 'max_depth': 10, 'learning_rate': 0.24141472011726225, 'subsample': 0.6178273431710068, 'colsample_bytree': 0.542278734200758, 'gamma': 4.883407735599985}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:22,798] Trial 96 finished with value: 0.5693939434522205 and parameters: {'n_estimators': 285, 'max_depth': 10, 'learning_rate': 0.2936372099736887, 'subsample': 0.6446509483223248, 'colsample_bytree': 0.9835480350680298, 'gamma': 4.436065030236963}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:23,196] Trial 97 finished with value: 0.5310134869123664 and parameters: {'n_estimators': 321, 'max_depth': 10, 'learning_rate': 0.2947946734814362, 'subsample': 0.662124774369794, 'colsample_bytree': 0.9868254967453146, 'gamma': 4.122719071955885}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:23,654] Trial 98 finished with value: 0.567023156346987 and parameters: {'n_estimators': 385, 'max_depth': 9, 'learning_rate': 0.2736802176786992, 'subsample': 0.636217546622276, 'colsample_bytree': 0.9476057156578112, 'gamma': 4.472812674754985}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:24,070] Trial 99 finished with value: 0.5422162788630797 and parameters: {'n_estimators': 285, 'max_depth': 5, 'learning_rate': 0.29959976317024123, 'subsample': 0.5718886510843334, 'colsample_bytree': 0.9923302701372662, 'gamma': 4.3131708067677925}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:24,760] Trial 100 finished with value: 0.5344052957215275 and parameters: {'n_estimators': 407, 'max_depth': 6, 'learning_rate': 0.2890135167849696, 'subsample': 0.6470441373149871, 'colsample_bytree': 0.8721040456011087, 'gamma': 0.727590377230015}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:25,062] Trial 101 finished with value: 0.5173730119548762 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.28114672440428684, 'subsample': 0.6056516864946337, 'colsample_bytree': 0.9670207250177272, 'gamma': 4.614334719658106}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:25,365] Trial 102 finished with value: 0.5633249443812132 and parameters: {'n_estimators': 345, 'max_depth': 10, 'learning_rate': 0.2635752248343589, 'subsample': 0.9811953863307421, 'colsample_bytree': 0.8987866737341726, 'gamma': 4.76453769585487}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:25,763] Trial 103 finished with value: 0.5542678397106725 and parameters: {'n_estimators': 216, 'max_depth': 10, 'learning_rate': 0.250058280191914, 'subsample': 0.5903878233845493, 'colsample_bytree': 0.9273559366210402, 'gamma': 3.3894714578833876}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:26,161] Trial 104 finished with value: 0.5342388149114571 and parameters: {'n_estimators': 279, 'max_depth': 10, 'learning_rate': 0.2578111837952949, 'subsample': 0.6126592250821589, 'colsample_bytree': 0.5319930321094967, 'gamma': 2.586774008375307}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:26,414] Trial 105 finished with value: 0.5668879964113585 and parameters: {'n_estimators': 238, 'max_depth': 9, 'learning_rate': 0.27004015616413807, 'subsample': 0.6562188620337857, 'colsample_bytree': 0.5586819297215866, 'gamma': 4.459263597244335}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:26,784] Trial 106 finished with value: 0.5656040675064223 and parameters: {'n_estimators': 251, 'max_depth': 10, 'learning_rate': 0.23380601803404893, 'subsample': 0.5770593815738533, 'colsample_bytree': 0.7427366372539324, 'gamma': 4.5510184489681675}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:27,118] Trial 107 finished with value: 0.5364571678607147 and parameters: {'n_estimators': 303, 'max_depth': 7, 'learning_rate': 0.2937998977464269, 'subsample': 0.5522755390215269, 'colsample_bytree': 0.6201229832815088, 'gamma': 4.19623359581673}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:27,569] Trial 108 finished with value: 0.551734151412548 and parameters: {'n_estimators': 325, 'max_depth': 10, 'learning_rate': 0.22413901170917835, 'subsample': 0.5342781293198541, 'colsample_bytree': 0.7196206254057548, 'gamma': 4.052829021563411}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:28,001] Trial 109 finished with value: 0.5413768050125641 and parameters: {'n_estimators': 371, 'max_depth': 10, 'learning_rate': 0.28050818244176245, 'subsample': 0.6294958842485693, 'colsample_bytree': 0.5987539441089099, 'gamma': 4.867237361746198}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:28,844] Trial 110 finished with value: 0.5406850865405022 and parameters: {'n_estimators': 458, 'max_depth': 8, 'learning_rate': 0.16150115410301552, 'subsample': 0.7708342833169379, 'colsample_bytree': 0.9841618390889739, 'gamma': 1.4929469817296108}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:29,224] Trial 111 finished with value: 0.5417124204159278 and parameters: {'n_estimators': 338, 'max_depth': 10, 'learning_rate': 0.23754599281388747, 'subsample': 0.5643972342033338, 'colsample_bytree': 0.5321225819164622, 'gamma': 4.55112637604938}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:29,674] Trial 112 finished with value: 0.5524903050892085 and parameters: {'n_estimators': 335, 'max_depth': 10, 'learning_rate': 0.24543659940336607, 'subsample': 0.5599203033686331, 'colsample_bytree': 0.9636821856891815, 'gamma': 4.365090495046197}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:30,020] Trial 113 finished with value: 0.5615048898506906 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.2160611599684026, 'subsample': 0.5453389150627483, 'colsample_bytree': 0.5823413907497782, 'gamma': 4.6874736945478785}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:30,524] Trial 114 finished with value: 0.5315307533067679 and parameters: {'n_estimators': 479, 'max_depth': 10, 'learning_rate': 0.1705998164150248, 'subsample': 0.5983118091134041, 'colsample_bytree': 0.5418323142181497, 'gamma': 4.789188769005249}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:31,114] Trial 115 finished with value: 0.5421950454600961 and parameters: {'n_estimators': 788, 'max_depth': 10, 'learning_rate': 0.19985752231175616, 'subsample': 0.6442431674550207, 'colsample_bytree': 0.5151600060170072, 'gamma': 4.451333302917827}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:31,883] Trial 116 finished with value: 0.5689851004766135 and parameters: {'n_estimators': 293, 'max_depth': 9, 'learning_rate': 0.020188938068717632, 'subsample': 0.5184876534562427, 'colsample_bytree': 0.5651964658852796, 'gamma': 4.65391553892411}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:32,181] Trial 117 finished with value: 0.5777646010293787 and parameters: {'n_estimators': 218, 'max_depth': 9, 'learning_rate': 0.2943775729346582, 'subsample': 0.5162311417226688, 'colsample_bytree': 0.5730168674564303, 'gamma': 4.885191567984055}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:32,747] Trial 118 finished with value: 0.5577651904613316 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.03057472894575912, 'subsample': 0.5176492357355947, 'colsample_bytree': 0.573525912355628, 'gamma': 4.9766785809435845}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:33,225] Trial 119 finished with value: 0.5266810524829835 and parameters: {'n_estimators': 515, 'max_depth': 9, 'learning_rate': 0.2876185124229555, 'subsample': 0.5040030752795602, 'colsample_bytree': 0.5526774612832572, 'gamma': 3.9151612393702258}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:33,534] Trial 120 finished with value: 0.5676040400411553 and parameters: {'n_estimators': 187, 'max_depth': 8, 'learning_rate': 0.29350820886040246, 'subsample': 0.5265294469792883, 'colsample_bytree': 0.5637996071085091, 'gamma': 4.6593831581900895}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:33,933] Trial 121 finished with value: 0.5475094203280341 and parameters: {'n_estimators': 215, 'max_depth': 9, 'learning_rate': 0.29911918266016235, 'subsample': 0.5128448241129089, 'colsample_bytree': 0.9451069928857033, 'gamma': 4.900176541385647}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:34,289] Trial 122 finished with value: 0.5673156733068251 and parameters: {'n_estimators': 245, 'max_depth': 9, 'learning_rate': 0.281357484125688, 'subsample': 0.5387038290001761, 'colsample_bytree': 0.6178308943476926, 'gamma': 4.7308046798489505}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:34,683] Trial 123 finished with value: 0.5578109423127948 and parameters: {'n_estimators': 285, 'max_depth': 10, 'learning_rate': 0.27463231239548996, 'subsample': 0.527249228153018, 'colsample_bytree': 0.6460058616159432, 'gamma': 4.354425941447236}. Best is trial 81 with value: 0.585264759407509.\n",
      "[I 2025-08-24 12:00:35,200] Trial 124 finished with value: 0.5255793546990413 and parameters: {'n_estimators': 570, 'max_depth': 10, 'learning_rate': 0.188099141981728, 'subsample': 0.5491088096288683, 'colsample_bytree': 0.5988718850684821, 'gamma': 4.821018707334717}. Best is trial 81 with value: 0.585264759407509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Params: {'n_estimators': 323, 'max_depth': 10, 'learning_rate': 0.2430417370516384, 'subsample': 0.5577559366087779, 'colsample_bytree': 0.5532866559353881, 'gamma': 4.516002265875756}\n",
      "Final Tuned XGBoost F1 Score: 0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/24 12:00:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:00:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025/08/24 12:00:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAP analysis complete and plot logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Run the study to find the best params\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=125) \n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best XGBoost Params:\", best_params)\n",
    "\n",
    "# Train the final XGBoost model with the best parameters and log to MLflow\n",
    "with mlflow.start_run(run_name=\"XGBoost_Tuned_Champion\") as run:\n",
    "    final_xgb_model = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "    final_xgb_model.fit(X_train, y_train)\n",
    "    y_pred_xgb = final_xgb_model.predict(X_test)\n",
    "    y_pred_proba_xgb = final_xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred_xgb)\n",
    "    print(f\"Final Tuned XGBoost F1 Score: {f1:.4f}\")\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred_xgb))\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc_score(y_test, y_pred_proba_xgb))\n",
    "\n",
    "    mlflow.xgboost.log_model(final_xgb_model, \"xgb-model\")\n",
    "    champion_run_id = run.info.run_id # Capture run ID\n",
    "\n",
    "    # --- SHAP Plot Generation and Logging (Move these lines here) ---\n",
    "    print(\"\\nSHAP analysis complete and plot logged to MLflow.\")\n",
    "\n",
    "    # 1. Create a SHAP Explainer\n",
    "    explainer = shap.TreeExplainer(final_xgb_model)\n",
    "    shap_values = explainer.shap_values(X_test) # Or X_train, depending on what you want to explain\n",
    "\n",
    "    # 2. Generate and save the SHAP summary plot to a temporary file\n",
    "    # Ensure you import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(10, 8)) # You might want to specify figure size\n",
    "    shap.summary_plot(shap_values, X_test, show=False, plot_size=(8, 6)) # show=False prevents immediate display\n",
    "    plt.title(\"SHAP Feature Importance for XGBoost Model\") # Add a title\n",
    "    plot_filename = \"shap_summary_champion.png\" # Give it a more descriptive name\n",
    "    plt.savefig(plot_filename, bbox_inches='tight', dpi=300) # Save the plot to a file\n",
    "    plt.close() # Close the plot to free memory\n",
    "\n",
    "    # 3. Log the saved plot as an MLflow artifact to the *current* active run\n",
    "    mlflow.log_artifact(plot_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464cccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully scaled.\n",
      "Shape of scaled training data: (2380, 32)\n"
     ]
    }
   ],
   "source": [
    "# --- MLP Challenger Model ---\n",
    "# Step 1: Imports and Data Scaling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Deep learning models are sensitive to feature scale. We must standardize our data.\n",
    "# We fit the scaler ONLY on the training data to prevent data leakage from the test set.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data successfully scaled.\")\n",
    "print(f\"Shape of scaled training data: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Tensors and DataLoaders created.\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy arrays to PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders to handle batching\n",
    "# We don't shuffle time-series data to preserve temporal order if needed, \n",
    "# but for a simple MLP, shuffling is often acceptable. Let's keep it False for rigor.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"PyTorch Tensors and DataLoaders created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c556ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model Architecture:\n",
      "ETF_MLP(\n",
      "  (layer_1): Linear(in_features=32, out_features=128, bias=True)\n",
      "  (bn_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer_2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (bn_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define the MLP Architecture\n",
    "class ETF_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1=128, hidden_size_2=64, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        Initializes the MLP model.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): The number of input features.\n",
    "            hidden_size_1 (int): Number of neurons in the first hidden layer.\n",
    "            hidden_size_2 (int): Number of neurons in the second hidden layer.\n",
    "            dropout_rate (float): The dropout probability.\n",
    "        \"\"\"\n",
    "        super(ETF_MLP, self).__init__()\n",
    "        \n",
    "        # --- Layer Definitions ---\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_size_1)\n",
    "        self.bn_1 = nn.BatchNorm1d(hidden_size_1)\n",
    "        \n",
    "        self.layer_2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.bn_2 = nn.BatchNorm1d(hidden_size_2)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_size_2, 1)\n",
    "        \n",
    "        # --- Activation and Regularization ---\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" The forward pass of the model. \"\"\"\n",
    "        # First hidden layer\n",
    "        x = self.layer_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second hidden layer\n",
    "        x = self.layer_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output layer with sigmoid for binary classification\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model to test\n",
    "input_features = X_train.shape[1]\n",
    "model_mlp = ETF_MLP(input_size=input_features)\n",
    "print(\"MLP Model Architecture:\")\n",
    "print(model_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/24 12:00:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MLP F1 Score from manual run: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/24 12:00:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Manual MLP Training and Evaluation\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_SIZE = X_train.shape[1]\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "\n",
    "# --- Model, Loss, Optimizer (Demonstrates 5.2, 5.3) ---\n",
    "model_mlp = ETF_MLP(input_size=INPUT_SIZE, dropout_rate=0.4)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model_mlp.parameters(), lr=LEARNING_RATE) # Adam Optimizer\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS) # LR Schedule\n",
    "\n",
    "# --- MLflow Logging ---\n",
    "with mlflow.start_run(run_name=\"MLP_Manual_Baseline\") as run:\n",
    "    mlflow.log_params({\"learning_rate\": LEARNING_RATE, \"epochs\": EPOCHS, \"optimizer\": \"Adam\"})\n",
    "    \n",
    "    # --- Training Loop ---\n",
    "    for epoch in range(EPOCHS):\n",
    "        model_mlp.train() # Set model to training mode\n",
    "        for features, labels in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model_mlp(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # --- Evaluation on Test Set ---\n",
    "        model_mlp.eval() # Set model to evaluation mode\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_loader:\n",
    "                outputs = model_mlp(features)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                all_preds.extend(predicted.numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "        \n",
    "        # Calculate and log F1 score for the epoch\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        mlflow.log_metric(\"test_f1_score\", f1, step=epoch)\n",
    "\n",
    "    print(f\"Final MLP F1 Score from manual run: {f1:.4f}\")\n",
    "    # Log the final model\n",
    "    mlflow.pytorch.log_model(model_mlp, \"mlp-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d750cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics and Parameters for 'ETF_Trend_Prediction' Experiment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run Name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>run_id</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>metrics.test_f1_score</th>\n",
       "      <th>params.gamma</th>\n",
       "      <th>params.colsample_bytree</th>\n",
       "      <th>params.subsample</th>\n",
       "      <th>params.n_estimators</th>\n",
       "      <th>params.max_depth</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>params.epochs</th>\n",
       "      <th>params.optimizer</th>\n",
       "      <th>params.model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>2025-08-24 15:58:54.572000+00:00</td>\n",
       "      <td>888d6b3008434f2eaeb138f684837161</td>\n",
       "      <td>0.535242</td>\n",
       "      <td>0.696839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>2025-08-24 15:58:54.838000+00:00</td>\n",
       "      <td>c0b547593f5743c8a1894ab0ba6819a5</td>\n",
       "      <td>0.527533</td>\n",
       "      <td>0.629853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_Tuned_Champion</td>\n",
       "      <td>2025-08-24 16:00:35.234000+00:00</td>\n",
       "      <td>b487ca5ed6b34ebaa3426cbef8158455</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.612676</td>\n",
       "      <td>0.50339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.516002265875756</td>\n",
       "      <td>0.5532866559353881</td>\n",
       "      <td>0.5577559366087779</td>\n",
       "      <td>323</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2430417370516384</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP_Manual_Baseline</td>\n",
       "      <td>2025-08-24 16:00:44.751000+00:00</td>\n",
       "      <td>79e20fbb9d2a4673979cf643049e1077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.162912</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_Champion_Training</td>\n",
       "      <td>2025-08-24 15:58:10.677000+00:00</td>\n",
       "      <td>76bf92fc01114e96a5f2453389ceee25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Run Name                       start_time  \\\n",
       "0           LogisticRegression_Baseline 2025-08-24 15:58:54.572000+00:00   \n",
       "1                 RandomForest_Baseline 2025-08-24 15:58:54.838000+00:00   \n",
       "2                XGBoost_Tuned_Champion 2025-08-24 16:00:35.234000+00:00   \n",
       "3                   MLP_Manual_Baseline 2025-08-24 16:00:44.751000+00:00   \n",
       "4  LogisticRegression_Champion_Training 2025-08-24 15:58:10.677000+00:00   \n",
       "\n",
       "                             run_id  Accuracy  F1 Score  ROC AUC  \\\n",
       "0  888d6b3008434f2eaeb138f684837161  0.535242  0.696839      NaN   \n",
       "1  c0b547593f5743c8a1894ab0ba6819a5  0.527533  0.629853      NaN   \n",
       "2  b487ca5ed6b34ebaa3426cbef8158455  0.515419  0.612676  0.50339   \n",
       "3  79e20fbb9d2a4673979cf643049e1077       NaN       NaN      NaN   \n",
       "4  76bf92fc01114e96a5f2453389ceee25       NaN       NaN      NaN   \n",
       "\n",
       "   metrics.test_f1_score       params.gamma params.colsample_bytree  \\\n",
       "0                    NaN               None                    None   \n",
       "1                    NaN               None                    None   \n",
       "2                    NaN  4.516002265875756      0.5532866559353881   \n",
       "3               0.162912               None                    None   \n",
       "4               0.685714               None                    None   \n",
       "\n",
       "     params.subsample params.n_estimators params.max_depth  \\\n",
       "0                None                None             None   \n",
       "1                None                None             None   \n",
       "2  0.5577559366087779                 323               10   \n",
       "3                None                None             None   \n",
       "4                None                None             None   \n",
       "\n",
       "  params.learning_rate params.epochs params.optimizer   params.model_type  \n",
       "0                 None          None             None                None  \n",
       "1                 None          None             None                None  \n",
       "2   0.2430417370516384          None             None                None  \n",
       "3                0.001            50             Adam                None  \n",
       "4                 None          None             None  LogisticRegression  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure MLflow is pointing to your tracking server/directory\n",
    "# mlflow.set_tracking_uri(\"../mlruns\") # Uncomment if running in a new session/script\n",
    "\n",
    "# Get the experiment by its name\n",
    "experiment = mlflow.get_experiment_by_name(\"ETF_Trend_Prediction\")\n",
    "\n",
    "if experiment:\n",
    "    # Search for all runs within this experiment\n",
    "    runs_df = mlflow.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        # Order by F1 score (desc) and then by start time (desc)\n",
    "        order_by=[\"metrics.f1_score DESC\", \"start_time DESC\"],\n",
    "        output_format=\"pandas\"\n",
    "    )\n",
    "\n",
    "    # --- New Logic to Extract All Metrics and Parameters ---\n",
    "    # Identify all metric and parameter columns\n",
    "    metric_cols = [col for col in runs_df.columns if col.startswith(\"metrics.\")]\n",
    "    param_cols = [col for col in runs_df.columns if col.startswith(\"params.\")]\n",
    "\n",
    "    # Select core run info, all metrics, and all parameters\n",
    "    # The 'tags.mlflow.runName' contains the run name\n",
    "    selected_cols = [\n",
    "        \"tags.mlflow.runName\", \"start_time\", \"run_id\"\n",
    "    ] + metric_cols + param_cols\n",
    "\n",
    "    metrics_and_params = runs_df[selected_cols].copy()\n",
    "\n",
    "    # Rename columns for better readability (optional, you can keep original for params if many)\n",
    "    # This example renames just the core and metric columns\n",
    "    metrics_and_params.rename(columns={\n",
    "        \"tags.mlflow.runName\": \"Run Name\",\n",
    "        \"metrics.f1_score\": \"F1 Score\",\n",
    "        \"metrics.accuracy\": \"Accuracy\",\n",
    "        \"metrics.roc_auc\": \"ROC AUC\"\n",
    "        # Add more renames for specific metrics/params if you want,\n",
    "        # but for ALL params, it might be too many to rename individually.\n",
    "        # Keeping 'params.param_name' is often fine.\n",
    "    }, inplace=True)\n",
    "\n",
    "    print(\"Metrics and Parameters for 'ETF_Trend_Prediction' Experiment:\")\n",
    "    display(metrics_and_params)\n",
    "\n",
    "else:\n",
    "    print(f\"Experiment 'ETF_Trend_Prediction' not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
