{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dca4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import shap\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load your processed data\n",
    "DATA_PATH = '../data/processed/etf_features.parquet'\n",
    "data = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7dc1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 11:49:42 INFO mlflow.tracking.fluent: Experiment with name 'ETF_Trend_Prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2380\n",
      "Test set size: 908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/dawso/Dev/Personal/AIGrind/mlops-etf-forecasting/notebooks/mlruns/587245152497429123', creation_time=1755964182346, experiment_id='587245152497429123', last_update_time=1755964182346, lifecycle_stage='active', name='ETF_Trend_Prediction', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the chronological split point\n",
    "# For example, use data up to the end of 2021 for training, and 2022 onwards for testing.\n",
    "split_date = '2022-01-01'\n",
    "X_train, X_test = X.loc[:split_date], X.loc[split_date:]\n",
    "y_train, y_test = y.loc[:split_date], y.loc[split_date:]\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "mlflow.set_experiment(\"ETF_Trend_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b6db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.6968\n",
      "Random Forest F1 Score: 0.6242\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Baseline\"):\n",
    "    model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    y_pred_lr = model_lr.predict(X_test)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred_lr))\n",
    "    mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred_lr))\n",
    "    print(f\"Logistic Regression F1 Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Train Random Forest\n",
    "with mlflow.start_run(run_name=\"RandomForest_Baseline\"):\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred_rf))\n",
    "    mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred_rf))\n",
    "    print(f\"Random Forest F1 Score: {f1_score(y_test, y_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05dee337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    # Use TimeSeriesSplit for robust cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring='f1', n_jobs=-1).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40b1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 11:50:05,846] A new study created in memory with name: no-name-947cf6b0-fb25-4850-9f4c-93c826c4667c\n",
      "[I 2025-08-23 11:50:12,258] Trial 0 finished with value: 0.5479968395472907 and parameters: {'n_estimators': 920, 'max_depth': 9, 'learning_rate': 0.01128201100741125, 'subsample': 0.6153642174913793, 'colsample_bytree': 0.9961571665220094, 'gamma': 2.854272440093066}. Best is trial 0 with value: 0.5479968395472907.\n",
      "[I 2025-08-23 11:50:15,171] Trial 1 finished with value: 0.5065589187226617 and parameters: {'n_estimators': 813, 'max_depth': 10, 'learning_rate': 0.1418325572862168, 'subsample': 0.9543419163932172, 'colsample_bytree': 0.846499658757347, 'gamma': 4.347146490084573}. Best is trial 0 with value: 0.5479968395472907.\n",
      "[I 2025-08-23 11:50:18,154] Trial 2 finished with value: 0.5091366625747832 and parameters: {'n_estimators': 772, 'max_depth': 5, 'learning_rate': 0.1392702940553672, 'subsample': 0.7387203990206367, 'colsample_bytree': 0.6061308984965355, 'gamma': 2.037879304267345}. Best is trial 0 with value: 0.5479968395472907.\n",
      "[I 2025-08-23 11:50:20,389] Trial 3 finished with value: 0.5664277354249379 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.06585060102528527, 'subsample': 0.9404693219008825, 'colsample_bytree': 0.8894787063246798, 'gamma': 4.939622843605439}. Best is trial 3 with value: 0.5664277354249379.\n",
      "[I 2025-08-23 11:50:20,944] Trial 4 finished with value: 0.49821874441725134 and parameters: {'n_estimators': 328, 'max_depth': 7, 'learning_rate': 0.22199714879103394, 'subsample': 0.829918640836349, 'colsample_bytree': 0.7777956844781408, 'gamma': 0.4592822303089361}. Best is trial 3 with value: 0.5664277354249379.\n",
      "[I 2025-08-23 11:50:22,264] Trial 5 finished with value: 0.5251672998570556 and parameters: {'n_estimators': 697, 'max_depth': 4, 'learning_rate': 0.07117279997822372, 'subsample': 0.7308818840520108, 'colsample_bytree': 0.9166612006220911, 'gamma': 0.20667615193343702}. Best is trial 3 with value: 0.5664277354249379.\n",
      "[I 2025-08-23 11:50:22,695] Trial 6 finished with value: 0.5337039317734222 and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.18499131816574133, 'subsample': 0.8279259556767272, 'colsample_bytree': 0.6464132355314931, 'gamma': 0.027090615436413668}. Best is trial 3 with value: 0.5664277354249379.\n",
      "[I 2025-08-23 11:50:23,467] Trial 7 finished with value: 0.5731417516950037 and parameters: {'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.018264800505261282, 'subsample': 0.652991272014374, 'colsample_bytree': 0.9608237263516124, 'gamma': 1.0354840908997605}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:24,072] Trial 8 finished with value: 0.5218966301938508 and parameters: {'n_estimators': 494, 'max_depth': 7, 'learning_rate': 0.2119807713140114, 'subsample': 0.9695461077824069, 'colsample_bytree': 0.6435000251434957, 'gamma': 0.22091748920763654}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:24,347] Trial 9 finished with value: 0.51512621953476 and parameters: {'n_estimators': 301, 'max_depth': 9, 'learning_rate': 0.25869131341544355, 'subsample': 0.9605159305181157, 'colsample_bytree': 0.6732494150568141, 'gamma': 2.437259155199976}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:24,835] Trial 10 finished with value: 0.5222165633104486 and parameters: {'n_estimators': 537, 'max_depth': 3, 'learning_rate': 0.027987821706798893, 'subsample': 0.5092876112972838, 'colsample_bytree': 0.505954697218107, 'gamma': 1.3381200760944991}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:25,061] Trial 11 finished with value: 0.5647779715433473 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.0769018623860392, 'subsample': 0.6215312704753438, 'colsample_bytree': 0.9733732554607761, 'gamma': 4.887320595624405}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:25,508] Trial 12 finished with value: 0.5441290303108643 and parameters: {'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.07813633268460528, 'subsample': 0.6447232508688007, 'colsample_bytree': 0.8800128620351242, 'gamma': 3.45717840929518}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:26,471] Trial 13 finished with value: 0.5190806321033843 and parameters: {'n_estimators': 207, 'max_depth': 8, 'learning_rate': 0.04938004302471159, 'subsample': 0.866224332541437, 'colsample_bytree': 0.8095281106399057, 'gamma': 1.1428324604506153}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:26,925] Trial 14 finished with value: 0.5316468806892879 and parameters: {'n_estimators': 408, 'max_depth': 5, 'learning_rate': 0.10551855871689285, 'subsample': 0.5401171784232074, 'colsample_bytree': 0.9235584619965532, 'gamma': 3.5020738251886563}. Best is trial 7 with value: 0.5731417516950037.\n",
      "[I 2025-08-23 11:50:27,194] Trial 15 finished with value: 0.6076752969275147 and parameters: {'n_estimators': 215, 'max_depth': 3, 'learning_rate': 0.010338381774272903, 'subsample': 0.693272401944256, 'colsample_bytree': 0.7380256387178412, 'gamma': 1.509407674529806}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:27,662] Trial 16 finished with value: 0.5464351389409836 and parameters: {'n_estimators': 414, 'max_depth': 3, 'learning_rate': 0.01421534792467946, 'subsample': 0.6772914590706172, 'colsample_bytree': 0.7200132777489483, 'gamma': 1.4818600978980625}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:28,179] Trial 17 finished with value: 0.551086590137287 and parameters: {'n_estimators': 641, 'max_depth': 4, 'learning_rate': 0.2913842755924184, 'subsample': 0.691172335577005, 'colsample_bytree': 0.7315704379025036, 'gamma': 0.9111985736273429}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:28,522] Trial 18 finished with value: 0.5287569638093632 and parameters: {'n_estimators': 249, 'max_depth': 4, 'learning_rate': 0.10525543105528709, 'subsample': 0.5725856464409923, 'colsample_bytree': 0.5547449148153625, 'gamma': 1.8531053358326959}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:30,250] Trial 19 finished with value: 0.5272500669331771 and parameters: {'n_estimators': 428, 'max_depth': 8, 'learning_rate': 0.04089716070364657, 'subsample': 0.7856407167213151, 'colsample_bytree': 0.799145360674656, 'gamma': 0.787647910473831}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:30,407] Trial 20 finished with value: 0.5364907900080741 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.11831754724879903, 'subsample': 0.5703863232940145, 'colsample_bytree': 0.7018252369639387, 'gamma': 1.8077436049019426}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:30,856] Trial 21 finished with value: 0.5189355720545186 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.05324279512338826, 'subsample': 0.8845133264848699, 'colsample_bytree': 0.9469495061344505, 'gamma': 2.5985456870529333}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:32,047] Trial 22 finished with value: 0.5728870282480687 and parameters: {'n_estimators': 338, 'max_depth': 7, 'learning_rate': 0.010320603137289192, 'subsample': 0.685572010804357, 'colsample_bytree': 0.8617162804251866, 'gamma': 3.9122536106465002}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:33,476] Trial 23 finished with value: 0.5672484913363773 and parameters: {'n_estimators': 379, 'max_depth': 8, 'learning_rate': 0.011948169115574387, 'subsample': 0.6955678577810527, 'colsample_bytree': 0.8327489989477377, 'gamma': 3.3695351587984286}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:33,903] Trial 24 finished with value: 0.533561197997583 and parameters: {'n_estimators': 256, 'max_depth': 7, 'learning_rate': 0.03856797118745253, 'subsample': 0.7787687634267647, 'colsample_bytree': 0.7652917022148193, 'gamma': 4.15241526411431}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:35,003] Trial 25 finished with value: 0.5553365296627245 and parameters: {'n_estimators': 329, 'max_depth': 9, 'learning_rate': 0.09096192616503046, 'subsample': 0.6692964374981933, 'colsample_bytree': 0.8754744754831914, 'gamma': 0.7600631067864374}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:36,120] Trial 26 finished with value: 0.5415361893609475 and parameters: {'n_estimators': 481, 'max_depth': 5, 'learning_rate': 0.03178490000240175, 'subsample': 0.6069919746387391, 'colsample_bytree': 0.9416686623780981, 'gamma': 2.18878413151966}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:36,584] Trial 27 finished with value: 0.5120011853849473 and parameters: {'n_estimators': 603, 'max_depth': 7, 'learning_rate': 0.17659498696582163, 'subsample': 0.7150179961494803, 'colsample_bytree': 0.8442956316863954, 'gamma': 3.0633989905272725}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:37,588] Trial 28 finished with value: 0.5340395256734742 and parameters: {'n_estimators': 230, 'max_depth': 10, 'learning_rate': 0.056840935177446664, 'subsample': 0.7639655427242106, 'colsample_bytree': 0.9726315338741496, 'gamma': 1.644467919979471}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:39,704] Trial 29 finished with value: 0.5430274663786847 and parameters: {'n_estimators': 899, 'max_depth': 8, 'learning_rate': 0.018186170227075915, 'subsample': 0.6499811659515276, 'colsample_bytree': 0.9971732976350453, 'gamma': 2.6984145704967704}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:40,642] Trial 30 finished with value: 0.5208881340215727 and parameters: {'n_estimators': 992, 'max_depth': 4, 'learning_rate': 0.030117249636887288, 'subsample': 0.6036440792492329, 'colsample_bytree': 0.7508159750278947, 'gamma': 4.051096163345156}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:42,222] Trial 31 finished with value: 0.5606705500174638 and parameters: {'n_estimators': 384, 'max_depth': 8, 'learning_rate': 0.01067685812031045, 'subsample': 0.6982490948244808, 'colsample_bytree': 0.8333733324651688, 'gamma': 3.3564182849414657}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:43,372] Trial 32 finished with value: 0.5714736951712233 and parameters: {'n_estimators': 367, 'max_depth': 9, 'learning_rate': 0.014165667547494128, 'subsample': 0.6510409194416854, 'colsample_bytree': 0.814263954820117, 'gamma': 3.9684885435780997}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:43,760] Trial 33 finished with value: 0.5698857679746834 and parameters: {'n_estimators': 142, 'max_depth': 9, 'learning_rate': 0.044548282626958285, 'subsample': 0.6324337646611825, 'colsample_bytree': 0.791700280392413, 'gamma': 4.508382711843508}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:44,559] Trial 34 finished with value: 0.5428828518215761 and parameters: {'n_estimators': 338, 'max_depth': 10, 'learning_rate': 0.028274129977798445, 'subsample': 0.7455038887874122, 'colsample_bytree': 0.8959963257605469, 'gamma': 3.8699303465091957}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:45,027] Trial 35 finished with value: 0.549644475772686 and parameters: {'n_estimators': 468, 'max_depth': 9, 'learning_rate': 0.13930010170537843, 'subsample': 0.6650703169857758, 'colsample_bytree': 0.8646140738735533, 'gamma': 3.8755816718935368}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:45,434] Trial 36 finished with value: 0.5286152403099379 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.06925628517855623, 'subsample': 0.5841326714140542, 'colsample_bytree': 0.8172357670917106, 'gamma': 4.553180697401035}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:45,905] Trial 37 finished with value: 0.5481424440064748 and parameters: {'n_estimators': 144, 'max_depth': 5, 'learning_rate': 0.052918918710407235, 'subsample': 0.7179332309362662, 'colsample_bytree': 0.9085843837805208, 'gamma': 2.317023109715813}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:46,923] Trial 38 finished with value: 0.5506184148508779 and parameters: {'n_estimators': 349, 'max_depth': 7, 'learning_rate': 0.0242002175516843, 'subsample': 0.5412259559630171, 'colsample_bytree': 0.7677426911506611, 'gamma': 2.9128876637373855}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:47,456] Trial 39 finished with value: 0.5207246134151244 and parameters: {'n_estimators': 208, 'max_depth': 6, 'learning_rate': 0.08716850793301466, 'subsample': 0.8013873396600745, 'colsample_bytree': 0.7023480502548903, 'gamma': 1.2787000442236016}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:48,383] Trial 40 finished with value: 0.546822216955817 and parameters: {'n_estimators': 550, 'max_depth': 9, 'learning_rate': 0.16104075095079037, 'subsample': 0.7275796494871208, 'colsample_bytree': 0.8522564423678227, 'gamma': 0.5159689202280581}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:48,778] Trial 41 finished with value: 0.5722345975524241 and parameters: {'n_estimators': 158, 'max_depth': 9, 'learning_rate': 0.04089016200274634, 'subsample': 0.6268830515721158, 'colsample_bytree': 0.7954656707306611, 'gamma': 4.5875667403598595}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:49,084] Trial 42 finished with value: 0.5674755050594628 and parameters: {'n_estimators': 168, 'max_depth': 9, 'learning_rate': 0.06258150545537927, 'subsample': 0.6549284769646606, 'colsample_bytree': 0.78724596433158, 'gamma': 4.665226093226572}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:50,113] Trial 43 finished with value: 0.5796061880806997 and parameters: {'n_estimators': 295, 'max_depth': 8, 'learning_rate': 0.010003937486425649, 'subsample': 0.6177090609267463, 'colsample_bytree': 0.7501565008179185, 'gamma': 4.279979793945014}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:50,509] Trial 44 finished with value: 0.5354303728871559 and parameters: {'n_estimators': 305, 'max_depth': 7, 'learning_rate': 0.040448212975542824, 'subsample': 0.6184459877666214, 'colsample_bytree': 0.6612123709242479, 'gamma': 4.860401636469685}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:50,977] Trial 45 finished with value: 0.6008330480277354 and parameters: {'n_estimators': 128, 'max_depth': 8, 'learning_rate': 0.0230434551000532, 'subsample': 0.5532139911743057, 'colsample_bytree': 0.7389991744030545, 'gamma': 4.361436650520024}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:51,468] Trial 46 finished with value: 0.5775306719252784 and parameters: {'n_estimators': 123, 'max_depth': 8, 'learning_rate': 0.0245546659117668, 'subsample': 0.5009831081866082, 'colsample_bytree': 0.6252123646797308, 'gamma': 3.578956415487433}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:51,647] Trial 47 finished with value: 0.5720976372593364 and parameters: {'n_estimators': 122, 'max_depth': 8, 'learning_rate': 0.23552628469196124, 'subsample': 0.5274793639257916, 'colsample_bytree': 0.61341149028867, 'gamma': 4.3703893590127745}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:52,208] Trial 48 finished with value: 0.5711876544908342 and parameters: {'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.02512911355229464, 'subsample': 0.5161366446302096, 'colsample_bytree': 0.5645479024837797, 'gamma': 3.7152366567066064}. Best is trial 15 with value: 0.6076752969275147.\n",
      "[I 2025-08-23 11:50:52,830] Trial 49 finished with value: 0.5256691955111729 and parameters: {'n_estimators': 743, 'max_depth': 8, 'learning_rate': 0.06705831364707404, 'subsample': 0.5581675859693611, 'colsample_bytree': 0.6123539519709914, 'gamma': 3.6374722038072647}. Best is trial 15 with value: 0.6076752969275147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Params: {'n_estimators': 215, 'max_depth': 3, 'learning_rate': 0.010338381774272903, 'subsample': 0.693272401944256, 'colsample_bytree': 0.7380256387178412, 'gamma': 1.509407674529806}\n",
      "Final Tuned XGBoost F1 Score: 0.6862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 11:50:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\dawso\\Dev\\Personal\\AIGrind\\mlops-etf-forecasting\\.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [11:50:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025/08/23 11:51:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Run the study to find the best params\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50) # Run for 50 trials\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best XGBoost Params:\", best_params)\n",
    "\n",
    "# Train the final XGBoost model with the best parameters and log to MLflow\n",
    "with mlflow.start_run(run_name=\"XGBoost_Tuned_Champion\") as run:\n",
    "    final_xgb_model = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "    final_xgb_model.fit(X_train, y_train)\n",
    "    y_pred_xgb = final_xgb_model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred_xgb)\n",
    "    print(f\"Final Tuned XGBoost F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Log everything to MLflow\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred_xgb))\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc_score(y_test, final_xgb_model.predict_proba(X_test)[:, 1]))\n",
    "    \n",
    "    # Save the model\n",
    "    mlflow.xgboost.log_model(final_xgb_model, \"xgb-model\")\n",
    "    \n",
    "    # Capture the run ID for later\n",
    "    champion_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8acbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP analysis complete and plot logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Explain the model's predictions using SHAP\n",
    "explainer = shap.TreeExplainer(final_xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Create and save the summary plot\n",
    "fig, ax = plt.subplots()\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.title(\"SHAP Feature Importance for XGBoost Model\")\n",
    "plt.savefig(\"shap_summary.png\")\n",
    "plt.close()\n",
    "\n",
    "# Log the SHAP plot as an artifact in the same MLflow run\n",
    "with mlflow.start_run(run_id=champion_run_id):\n",
    "    mlflow.log_artifact(\"shap_summary.png\")\n",
    "\n",
    "print(\"SHAP analysis complete and plot logged to MLflow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
